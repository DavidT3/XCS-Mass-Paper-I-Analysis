{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ca38d73",
   "metadata": {},
   "source": [
    "# Visualising and saving analysis regions for the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbdc738",
   "metadata": {},
   "source": [
    "This notebook exists only to generate combined (stacked or co-added) images of the galaxy clusters in our samples. The visualisations will have the initial $R_{500}$ and background regions overlaid, as well as contaminant source regions. They will then be saved to disk for future access/reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18907eb5",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf73311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.units import Quantity, UnitConversionError\n",
    "from astropy.cosmology import LambdaCDM, WMAP9\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Union, List\n",
    "from shutil import rmtree\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n",
    "\n",
    "# This adds the directory above to the path, allowing me to import the common functions that I've written in\n",
    "#  common.py - this just saves me repeating boring code and makes sure its all consistent\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from common import xcs3p_colour, xcs_cosmo, xxlgc100_colour, xxl_cosmo, locuss_colour, locuss_cosmo\n",
    "\n",
    "import xga\n",
    "# This just sets the number of cores this analysis is allowed to use\n",
    "xga.NUM_CORES = 100\n",
    "# This is a bodge that will only work because xga_output in notebooks has already been defined, XGA\n",
    "#  will be made to handle this more gracefully at some point\n",
    "temp_dir = xga.OUTPUT\n",
    "actual_dir = temp_dir.split('notebooks/')[0]+'notebooks/xga_output/'\n",
    "xga.OUTPUT = actual_dir\n",
    "xga.utils.OUTPUT = actual_dir\n",
    "# As currently XGA will setup an xga_output directory in our current directory, I remove it to keep it all clean\n",
    "if os.path.exists('xga_output'):\n",
    "    rmtree('xga_output')\n",
    "from xga.samples import ClusterSample\n",
    "from xga.products import Image\n",
    "from xga.imagetools.misc import physical_rad_to_pix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33555ca5",
   "metadata": {},
   "source": [
    "## Defining useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6f913d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57748b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_regions_visualisation(src, save_path, view=False):\n",
    "    rt = src.get_combined_ratemaps()\n",
    "    src_msk, bck_msk = src.get_mask('r500')\n",
    "    int_msk = src.get_interloper_mask()\n",
    "    \n",
    "    rpix = physical_rad_to_pix(rt, src.r500, src.default_coord, src.redshift, src.cosmo)\n",
    "    src_ann = Quantity([0, rpix.value], 'pix')\n",
    "    bck_ann = Quantity(rpix*src.background_radius_factors)\n",
    "    rt.regions = src._interloper_regions\n",
    "    \n",
    "    coords = Quantity([src.peak, src.ra_dec])\n",
    "\n",
    "    if view:\n",
    "        rt.view(coords, int_msk, radial_bins_pix=src_ann.value, back_bin_pix=bck_ann.value, zoom_in=True, \n",
    "                view_regions=True)\n",
    "    else:\n",
    "        rt.save_view(save_path, coords, int_msk, radial_bins_pix=src_ann.value, back_bin_pix=bck_ann.value, \n",
    "                     zoom_in=True, view_regions=True)\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eed232",
   "metadata": {},
   "source": [
    "## Reading in Sample Files and Declaring XGA ClusterSamples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46e5150",
   "metadata": {},
   "source": [
    "This subsection involves reading in the sample files of the four test samples (described in [the sample properties notebook](sample_properties.ipynb)), then setting up separate XGA ClusterSample instances (see [the documentation](https://xga.readthedocs.io/en/latest/notebooks/tutorials/sources_samples.html) for an introduction to XGA source and sample objects.\n",
    "\n",
    "We impose an additional cleaning step on each sample, where we make sure that (for each XMM observation initially associated with a source) at least 70% of a cluster's $R_{500}$ falls on that observation - if this requirement is not met then the observation is excluded. These requirements are set with the `clean_obs=True`, `clean_obs_reg='r500'`, and `clean_obs_threshold=0.7` arguments when a ClusterSample instance is declared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf00d24c",
   "metadata": {},
   "source": [
    "### SDSSRM-XCS Volume Limited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3269f883",
   "metadata": {},
   "source": [
    "This is the recent SDSSRM-XCS sample. The temperatures and luminosities are measured by the XCS luminosity-temperature pipeline, and with this we demonstrate that XGA temperatures and luminosities are consistent with existing XCS results.\n",
    "\n",
    "In order to achieve maximum consistency, we use the XAPA coordinates as the central position for spectrum generation (turning off the XGA peak finder with `use_peak=False`). We have also made sure to use the same cosmology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c3eb5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcs3p = pd.read_csv(\"../../sample_files/xcs3p_sdssrm_vol_lim_temperr_25%_clusters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f39185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Declaring BaseSource Sample: 100%|██████████████████████████████████████████| 150/150 [07:03<00:00,  2.83s/it]\n",
      "Setting up Galaxy Clusters: 100%|███████████████████████████████████████████| 150/150 [14:18<00:00,  5.73s/it]\n"
     ]
    }
   ],
   "source": [
    "# Reading out the relevant values into arrays just for ease of passing into the ClusterSample object\n",
    "ra = xcs3p['xapa_ra'].values\n",
    "dec = xcs3p['xapa_dec'].values\n",
    "z = xcs3p['z'].values\n",
    "# Not using the IAU names in XCS_NAME column, its easier for me to use the name based on redMaPPer ID\n",
    "n = xcs3p['name'].values\n",
    "# In arcminutes, ClusterSample declaration will convert to kpc using the provided cosmology\n",
    "r500 = Quantity(xcs3p['r500'].values, 'arcmin')\n",
    "# Not likely to use richness in this notebook, but I'm putting it in the sample object anyway\n",
    "r = xcs3p['richness'].values\n",
    "r_err = xcs3p['richness_err'].values\n",
    "\n",
    "# Declaring the actual ClusterSample instance for the XCS sample\n",
    "xcs_srcs = ClusterSample(ra, dec, z, n, r500=r500, richness=r, richness_err=r_err, cosmology=xcs_cosmo, \n",
    "                         load_fits=True, use_peak=True, clean_obs=True, clean_obs_reg='r500', \n",
    "                         clean_obs_threshold=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ac46f7",
   "metadata": {},
   "source": [
    "### XXL-100-GC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b240b5",
   "metadata": {},
   "source": [
    "This is the sample of the brightest clusters in the XXL survey. It contains temperature and luminosity measurements, and will be a useful external comparison for XGA results, though the shallow XXL data may prove a challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e44d5090",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxlgc100 = pd.read_csv(\"../../sample_files/xxl_gc100.csv\")\n",
    "\n",
    "# Limit the comparison to clusters with a flag of 0 - meaning it is in the main sample of 100 clusters\n",
    "xxlgc100 = xxlgc100[xxlgc100['Flag'] == 0]\n",
    "\n",
    "# Excluding a specific cluster which was excluded in the XXL analysis\n",
    "xxlgc100 = xxlgc100[xxlgc100['XLSSC'] != 504]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6e329dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Declaring BaseSource Sample: 100%|████████████████████████████████████████████| 99/99 [03:38<00:00,  2.21s/it]\n",
      "Setting up Galaxy Clusters: 100%|█████████████████████████████████████████████| 99/99 [13:46<00:00,  8.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# Reading out the relevant values into arrays just for ease of passing into the ClusterSample object\n",
    "ra = xxlgc100['ra'].values\n",
    "dec = xxlgc100['dec'].values\n",
    "z = xxlgc100['z'].values\n",
    "n = xxlgc100['name'].values\n",
    "r500 = Quantity(xxlgc100['r500MT'].values, 'Mpc')\n",
    "\n",
    "# Declaring the actual ClusterSample instance for the XXL sample\n",
    "# This is the only sample whose original analysis used the WMAP9 cosmology\n",
    "xxl_srcs = ClusterSample(ra, dec, z, n, r500=r500, cosmology=xxl_cosmo, load_fits=True, use_peak=True, \n",
    "                         clean_obs=True, clean_obs_reg='r500', clean_obs_threshold=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae081f4b",
   "metadata": {},
   "source": [
    "### LoCuSS High-$L_{\\rm{X}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7936d805",
   "metadata": {},
   "source": [
    "The LoCuSS High-$L_{\\rm{X}}$ sample was selected from ROSAT for its high luminosity clusters, and will again be a useful comparison as testing against various different analyses is beneficial in establishing the veracity of our new measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0738ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "locuss = pd.read_csv(\"../../sample_files/locuss_highlx_clusters.csv\", dtype={'chandra_id': str, 'xmm_obsid': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f2aee9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Declaring BaseSource Sample: 100%|████████████████████████████████████████████| 50/50 [06:58<00:00,  8.36s/it]\n",
      "Setting up Galaxy Clusters: 50it [07:45,  9.30s/it]                                                           \n"
     ]
    }
   ],
   "source": [
    "# Reading out the relevant values into arrays just for ease of passing into the ClusterSample object\n",
    "ra = locuss['ra'].values\n",
    "dec = locuss['dec'].values\n",
    "z = locuss['z'].values\n",
    "n = locuss['name'].values\n",
    "r500 = Quantity(locuss['r500'].values, 'kpc')\n",
    "r2500 = Quantity(locuss['r2500'].values, 'kpc')\n",
    "\n",
    "\n",
    "# Declaring the actual ClusterSample instance for the LoCuSS sample\n",
    "locuss_srcs = ClusterSample(ra, dec, z, n, r500=r500, r2500=r2500, cosmology=locuss_cosmo, load_fits=True, \n",
    "                            use_peak=True, clean_obs=True, clean_obs_reg='r500', clean_obs_threshold=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e5b693",
   "metadata": {},
   "source": [
    "## Visualising $R_{500}$ and $R^{\\rm{background}}_{500}$ regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f5750",
   "metadata": {},
   "source": [
    "Here we generate combined ratemaps for all the clusters in the samples, overlaying the $R_{500}$ analysis region (as a solid circle), the background annulus (enclosed by two dashed circles) which by default goes from [1.05-1.5]$R_{500}$, the X-ray peak coordinate measured by XGA (the solid white crosshair), and the original literature coordinate (the dashed white crosshair).\n",
    "\n",
    "We also mask the regions that XGA has defined as contaminants, and overlay their XCS region. Due to the large number of clusters in our various samples, we only display one cluster per sample here (as an example), and save all visualisations to the `cluster_visualisations/{sample name}` directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9e775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../../outputs/cluster_visualisations/sdssrm-xcs'):\n",
    "    os.makedirs('../../outputs/cluster_visualisations/sdssrm-xcs')\n",
    "\n",
    "if not os.path.exists('../../outputs/cluster_visualisations/xxl'):\n",
    "    os.makedirs('../../outputs/cluster_visualisations/xxl')\n",
    "    \n",
    "if not os.path.exists('../../outputs/cluster_visualisations/locuss'):\n",
    "    os.makedirs('../../outputs/cluster_visualisations/locuss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c4fcc8",
   "metadata": {},
   "source": [
    "### SDSSRM-XCS Volume Limited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbe6e7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis_regions_visualisation(xcs_srcs[0], \n",
    "                               '../../outputs/cluster_visualisations/sdssrm-xcs/{}.png'.format(xcs_srcs[0].name), \n",
    "                               view=True)\n",
    "for src in xcs_srcs:\n",
    "    analysis_regions_visualisation(src, '../../outputs/cluster_visualisations/sdssrm-xcs/{}.png'.format(src.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1198ed6",
   "metadata": {},
   "source": [
    "### XXL-100-GC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e15d37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis_regions_visualisation(xxl_srcs[0], \n",
    "                               '../../outputs/cluster_visualisations/xxl/{}.png'.format(xxl_srcs[0].name), \n",
    "                               view=True)\n",
    "for src in xxl_srcs:\n",
    "    analysis_regions_visualisation(src, '../../outputs/cluster_visualisations/xxl/{}.png'.format(src.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7577627f",
   "metadata": {},
   "source": [
    "### LoCuSS High-$L_{\\rm{X}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b50f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis_regions_visualisation(locuss_srcs[1], \n",
    "                               '../../outputs/cluster_visualisations/locuss/{}.png'.format(locuss_srcs[0].name), \n",
    "                               view=True)\n",
    "for src in locuss_srcs:\n",
    "    analysis_regions_visualisation(src, '../../outputs/cluster_visualisations/locuss/{}.png'.format(src.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075db144",
   "metadata": {},
   "source": [
    "## Identifying and saving which ObsIDs are used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5780501a",
   "metadata": {},
   "source": [
    "Here we just compile a list of ObsIDs that are used in the analysis of our three samples, also saving which clusters each particular ObsID is associated with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d344c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_ids = {}\n",
    "\n",
    "for samp in [xcs_srcs, xxl_srcs, locuss_srcs]:\n",
    "    for src in samp:\n",
    "        cur_rts = src.get_ratemaps(lo_en=Quantity(0.5, 'keV'), hi_en=Quantity(2.0, 'keV'))\n",
    "        if not isinstance(cur_rts, list):\n",
    "            cur_rts = [cur_rts]\n",
    "        for rt in cur_rts:\n",
    "            if rt.obs_id not in obs_ids:\n",
    "                obs_ids[rt.obs_id] = [src.name]\n",
    "            else:\n",
    "                obs_ids[rt.obs_id].append(src.name)\n",
    "\n",
    "obs_ids = {o: list(set(ns)) for o, ns in obs_ids.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b679508c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(obs_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d1a3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../outputs/obs_info.json', 'w') as writeo:\n",
    "    json.dump(obs_ids, writeo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
